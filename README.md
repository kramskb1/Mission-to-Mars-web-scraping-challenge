	I completed my initial scraping using Jupyter Notebook, BeautifulSoup, Pandas, and Requests/Splinter. I created a Jupyter Notebook file to complete all of my scraping and analysis tasks. I scraped the NASA Mars News Site and collected the latest News Title and Paragraph Text. I assigned the text to variables that I could reference later. I visited the url for JPL Featured Space Image. I used splinter to find the image url for the current featured Mars image. I assigned the url string to a variable called featured_image_url.
	I visited the USGS Astrogeology site to obtain high resolution images for each of Marsâ€™ hemispheres. I saved the url string for the full resolution hemisphere image, and the hemisphere title containing the hemisphere name. I used a Python dictionary to store the data using the keys img_url and title. I appended the dictionary with the url string and the hemisphere title to a list. The list contained one dictionary for each hemisphere. 
	I used MongoDB with Flask Templating to create a new HTML page that displayed all of the information from the URLs. I converted my Jupyter Notebook into a Python script called scrape_mars.py. It included a function called scrape which executed all of my scraping code and returned one Python dictionary containing all of the scraped data. I created a route called /scrape that imported my scrape_mars.py and called my scrape function. I stored the return value in Mongo as a Python dictionary.
	I created a root route / that queried my Mongo database and passed the Mars data into an HTML template to display the data. I created a file called index.html that took the mars data dictionary and displayed all of the data in the appropriate HTML elements. One issue that I had when completing this assignment was the chromedriver.exe file that I was using would work one day and then not work the next day. I had to update the chromedriver I was using on multiple occasions while completing this assignment. Otherwise, the chromedriver would sometimes prevent my webpages from loading.
	My Mars image was generated. My Valles Marineris image was generated.  My Cerberus Hemisphere image was generated. My Schiaparelli Hemisphere image was generated. My Syrtis Major Hemisphere image was generated. 
	I learned a lot about using Splinter, BeautifulSoup, Pymongo, and Bootstrap when completing this assignment. I used Splinter to navigate the sites when needed. I used BeautifulSoup to help find and parse out the necessary data. I used PyMonogo for CRUD applications for my database. I used Bootstrap to structure my HTML template. 
	My images are all visible in my Mission to Mars_files folder. My Missions to Mars folder contains my HTML code, my Jupyter notebook file, my scrape_mars.py file, my app.py file, and my chromedriver extension. In the middle of doing this assignment, my original chromedriver extension stopped working and I had to download the latest version of chromedriver extension and replace it with the one that I initially had. My Jupyter notebook file contains the news title, the news paragraph, and the feature image. It also includes a Mars facts table. My Jupyter notebook file also includes a for loop where I get each hemisphere title, get each hemisphere image URL, and I append each hemisphere information to the list of all hemispheres.
My scrape_mars.py file is my Jupyter notebook converted into a Python script with the scrape function included. I imported the Pymongo function into my app.py file. I created several routes in my app.py file. In my screenshots folder, my index screenshot is visible. Two screenshots of my HTML website created with my HTML code is also visible. My templates folder includes my index.html file.

	
